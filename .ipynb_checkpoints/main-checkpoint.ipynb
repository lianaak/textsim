{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3719)\t0.26397787257074184\n",
      "  (0, 3277)\t0.36256131667299346\n",
      "  (0, 3069)\t0.36256131667299346\n",
      "  (0, 6496)\t0.08943160911328076\n",
      "  (0, 9670)\t0.2915259992373719\n",
      "  (0, 8865)\t0.05950803659005052\n",
      "  (0, 2143)\t0.2210831299495613\n",
      "  (0, 4517)\t0.14933782308677898\n",
      "  (0, 9616)\t0.3319680706581691\n",
      "  (0, 2044)\t0.31407216896415985\n",
      "  (0, 4622)\t0.33720945167531796\n",
      "  (0, 1038)\t0.26724875570688483\n",
      "  (0, 1306)\t0.32516436460039067\n",
      "  (1, 1804)\t0.23066647034698415\n",
      "  (1, 466)\t0.26546700664355705\n",
      "  (1, 4034)\t0.1299069260571812\n",
      "  (1, 365)\t0.3013613774739738\n",
      "  (1, 4828)\t0.09462831365519349\n",
      "  (1, 7830)\t0.37091884070641773\n",
      "  (1, 8965)\t0.08705201463016644\n",
      "  (1, 2314)\t0.3213119531872382\n",
      "  (1, 8004)\t0.27894519932471895\n",
      "  (1, 1735)\t0.22804810589077187\n",
      "  (1, 3323)\t0.3892272669076743\n",
      "  (1, 6686)\t0.27340919753012966\n",
      "  :\t:\n",
      "  (4074, 6185)\t0.556388043736113\n",
      "  (4074, 6419)\t0.556388043736113\n",
      "  (4074, 2113)\t0.2326865716759268\n",
      "  (4074, 7569)\t0.3118119315062898\n",
      "  (4074, 9829)\t0.3016329582235035\n",
      "  (4074, 4123)\t0.34019659705384814\n",
      "  (4074, 1711)\t0.12016333771806544\n",
      "  (4074, 8865)\t0.09132127047844404\n",
      "  (4075, 662)\t0.34250550000371277\n",
      "  (4075, 435)\t0.34250550000371277\n",
      "  (4075, 9382)\t0.30609764328694467\n",
      "  (4075, 665)\t0.32639476675482687\n",
      "  (4075, 9556)\t0.32639476675482687\n",
      "  (4075, 9302)\t0.2713118059529833\n",
      "  (4075, 1915)\t0.23909033945521146\n",
      "  (4075, 546)\t0.2713118059529833\n",
      "  (4075, 9784)\t0.2376453090385102\n",
      "  (4075, 2495)\t0.1939930953887025\n",
      "  (4075, 6856)\t0.2797352513395221\n",
      "  (4075, 7689)\t0.19352286555515233\n",
      "  (4075, 1523)\t0.12810513197645756\n",
      "  (4075, 969)\t0.07477203722251718\n",
      "  (4075, 4034)\t0.11431325717916431\n",
      "  (4075, 6496)\t0.08051054498835461\n",
      "  (4075, 8865)\t0.05357193619297675\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from preprocess_data import processed_data\n",
    "#import collections\n",
    "#from typing import Dict, List, Tuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "def cosine_distance(s1, s2):   \n",
    "    vector_1 = np.mean([model[word] for word in preprocessing(s1)],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in preprocessing(s2)],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "   \n",
    "\n",
    "    \n",
    "#def text2bow(words: List[str], dictionary: Dict[str, int]) -> List[Tuple[int, int]]:\n",
    "#    word_frequences = collections.defaultdict(int)\n",
    "#    for word in words:\n",
    "#        if word not in dictionary:\n",
    "#            dictionary[word] = len(dictionary)\n",
    "#        word_frequences[dictionary[word]] += 1\n",
    "#    return list(word_frequences.items())\n",
    "    \n",
    "#dictionary = {}\n",
    "#for sentence1, sentence2 in zip(processed_data[1:,3],processed_data[1:,4]):\n",
    "#    text2bow(tuple(sentence1), dictionary)\n",
    "#    text2bow(tuple(sentence2), dictionary)\n",
    "    \n",
    "    \n",
    "#print('Dictionary:', dictionary)\n",
    "\n",
    "\n",
    "#text 2 bow with gensim\n",
    "def text2bow2(token_lists):\n",
    "    dictionary = corpora.Dictionary()\n",
    "    BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in token_lists]\n",
    "    id_words = [[(dictionary[id], count) for id, count in line] for line in BoW_corpus]\n",
    "    return BoW_corpus\n",
    "\n",
    "#print(text2bow2(processed_data[1:,3]))\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "def text2tfidf(token_lists):\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False)\n",
    "    result = tfidf_vectorizer.fit_transform(token_lists)\n",
    "    return result\n",
    "\n",
    "print(text2tfidf(processed_data[1:,3]))\n",
    "\n",
    "def text2w2v(token_lists):\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texttovec_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ffdc964794ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Obama\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"speaks\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"in\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Illinois\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcosine_distance_wordembedding_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-ab83ab82ef49>\u001b[0m in \u001b[0;36mcosine_distance_wordembedding_method\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcosine_distance_wordembedding_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mvector_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvector_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcosine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "s1 = [\"President\", \"greets\", \"the\", \"press\", \"in\",\"Chicago\"]\n",
    "s2 = [\"Obama\",\"speaks\", \"in\", \"Illinois\"]\n",
    "\n",
    "cosine_distance_wordembedding_method(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
